{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unit1_7_DataProcessing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"duZioUJfkhFI"},"source":["# Actors\n","\n","- Data Scientist: *The hospital employs him to stay in touch with current developments*\n","- Clinician: *She is a general practitioner, invited to join the discussions about the new setup of the Cardiovasular Disease Department*\n","- Cardiology expert: *An expert for cardiovascular disease, diagnoses patients day-in day-out*"]},{"cell_type":"markdown","metadata":{"id":"wNd2DmqDcVqE"},"source":["# Data processing to prepare for Machine Learning\n","\n","There are two types of values, categorical values and continuous values.\n","\n","On the one hand, categorical data is the data that can be stored into groups and don't have mathematical meaning. For example, in the feature \"gender\" we have 1(male) and 2(female) but they represent groups.\n","\n","On the other hand, continuous data represent a measurement with a mathematical meaning such as \"height\" and \"ap_hi\". That is, unlike the categorical ones, the higher the number, the more important it is."]},{"cell_type":"code","metadata":{"id":"mae3Xw-LchqB","cellView":"form"},"source":["#@markdown Identify categorical and continuous features\n","categorical_val = []\n","continous_val = []\n","\n","for column in cardio_modified.columns:\n","    # Considering a column with less than 10 unique values as categorical feature\n","    if len(cardio_modified[column].unique()) <= 10:\n","        categorical_val.append(column)\n","    else:\n","        continous_val.append(column)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0zj4VxnmckI7"},"source":["## Categorical features\n","\n","We have to consider making groups in some features to gain effectiveness in the prediction. For example, *age* is one continuous feature that we can group into 3:\n","\n","    - Young age 0 : <40\n","    - Middle age 1 : 40 - 55\n","    - Elderly age 2 : > 55"]},{"cell_type":"markdown","metadata":{"id":"9o0oY6ynCqkS"},"source":["Grouping all ages can also help to anonymize data. Imagine in your dataset are only very few, very old or very young patients. Only by knowing roughly where the data came from, they might be identified. "]},{"cell_type":"code","metadata":{"id":"J_7W45jOcmdc","cellView":"form"},"source":["#@markdown ### Perform age grouping\n","cardio_grouped = cardio_modified.copy()\n","\n","def groupAge(age):\n","    \n","    if age < 40:\n","        return 0\n","    elif 55 > age >= 40:\n","        return 1\n","    else:\n","        return 2\n","cardio_grouped['age'] = cardio_grouped['age'].apply(lambda x: groupAge(x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cOjUe9YC6SB"},"source":["After grouping all ages into three groups, let's assess the new age distribution with another histogram."]},{"cell_type":"code","metadata":{"id":"o2dsNlZQcvSj","cellView":"form"},"source":["#@markdown ### Plot age histrogram\n","cardio_grouped.hist('age', figsize=(10,10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZNp-exHc0Td"},"source":["In addition, we have to prepare our categorical features by separating the categories into columns in order to give the same importance to each group."]},{"cell_type":"code","metadata":{"id":"V6tVsQITc2CX","cellView":"form"},"source":["#@markdown ## Split categories into different columns\n","categorical_val.remove('cardio')\n","cardio_categorize = pd.get_dummies(cardio_grouped, columns = categorical_val)\n","\n","display(cardio_categorize)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S-QNv02yc48p"},"source":["## Continuous features\n","\n","On the other hand, normalizing continuous data is very important because our features have different range of values and this could skew the values and falsify the results. We have a range of the feature \"weight\" between 51-109 kg and a range of the feature \"ap_hi\" between 100-170 mmHg. If we don't normalize the data, the model will give more importance to mmHg because the range is higher. To avoid false results, let's normalize the data between 0 and 1."]},{"cell_type":"code","metadata":{"id":"HH2iVGrpc7Vf","cellView":"form"},"source":["#@markdown ## Min Max scaler\n","\n","# Normalize continuous features weight, ap_hi and ap_lo \n","cardio_scaled = cardio_categorize.copy()\n","scaler = MinMaxScaler()\n","columns_to_scale = ['weight', 'ap_hi', 'ap_lo']\n","cardio_scaled[columns_to_scale] = scaler.fit_transform(cardio_scaled[columns_to_scale])\n","display(cardio_scaled)\n","#cardio_scaled.to_csv (r'cardio_scaled.csv', index = False, header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hypMIE4BlKXG"},"source":["# Data dimensionality\n","\n","The main problems of working with large amounts of data is the dimensionality of this. When we have many features it can lead to poor performance and meaningless results because of the called \"curse of dimensionality\". \n","\n","Each column in the dataset represents a dimension and having a large number of dimensions in the feature space can mean a problem to compute algorithms and visualize results. Hence, it is desirable to reduce the number of dimensions. \n","\n","One of the techniques to solve that problem is Principal Component Analysis (PCA). It is an unsupervised learning algorithm used to reduce the dimensionality. \n","\n","<figure>\n","<br/>\n","<center>\n","<img src='https://drive.google.com/uc?id=1wfWKVWfXNqFt5Of2FbjHnraeplIhHoFy' width=500 height=250/>\n","<br/>\n","</figure>\n","\n","It projects the dataset onto a lower dimensional hyperplane keeping as much information as possible.\n","\n","\n","---\n","To play with an interactive tool visit http://projector.tensorflow.org/\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y227hH3wTd5s"},"source":["## **Exercises**\n","1. Why is it important to categorize the data?\n","\n","2. Why is it important to normalize the data?"]},{"cell_type":"markdown","metadata":{"id":"vuS4g-rvTzxp"},"source":["**==========================WRITE YOUR ANSWERS HERE==========================**"]}]}